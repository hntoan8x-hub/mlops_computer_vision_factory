# config/medical_training_config.yaml (Finalized Production Config)
# MLOps Configuration File for CV Training Workflow
# This file is validated against the TrainingOrchestratorConfig Pydantic Schema.

# --- GLOBAL METADATA (Used for Auditing/Traceability) ---
run_metadata:
  git_sha: "ABC123DEF456"
  config_hash: "HJK789LMN012"
  project_name: "medical_imaging_v2"
  run_tags: ["pneumonia", "classification", "ddp"] # Custom tags for MLflow

# --- 1. PIPELINE TYPE (Used by CVPipelineFactory) ---
pipeline_type: training

# --- 2. DATA INGESTION (Connector Setup) ---
data_ingestion:
  enabled: True
  connector_config:
    # We choose the Image connector, specifying its connection parameters
    type: image
    uri: "s3://cv-training-data-bucket/chest_xrays/"

    # Connection parameters for the ImageConnector (delegated to connector's __init__)
    connection_params:
      region: "us-east-1"
      max_retries: 3

  # Configuration for loading the metadata manifest (list of images and labels)
  metadata_uri: "s3://cv-training-data-bucket/manifests/train_manifest_v1.csv"

# --- 3. PREPROCESSING & FEATURE ENGINEERING ---
preprocessing:
  enabled: True

  # CLEANING: Mandatory steps applied to all data (Training and Inference)
  cleaning:
    steps:
      - type: resizer
        params:
          width: 224
          height: 224
          interpolation: 1 # cv2.INTER_LINEAR
      - type: normalizer
        params:
          mean: [0.485, 0.456, 0.406] # ImageNet means
          std: [0.229, 0.224, 0.225]
      - type: color_space
        params:
          conversion_code: "BGR2RGB"

  # AUGMENTATION: Optional steps (Enabled only for Training context)
  augmentation:
    enabled: True
    steps:
      - type: flip_rotate
        params:
          flip_prob: 0.5
          rotate_limit: 10
      - type: noise_injection
        params:
          noise_type: "gaussian"
          strength: 0.01

  # FEATURE ENGINEERING: Optional steps (e.g., using a pre-trained model as embedder)
  feature_engineering:
    components:
      - type: cnn_embedder # Uses the adapter we created
        params:
          model_name: "resnet18"
          pretrained: True
          remove_head: True

# --- 4. MODEL CONFIGURATION ---
model:
  enabled: True
  type: "cnn" # Model family
  name: "lung_disease_classifier"
  task_type: classification
  num_classes: 3
  weights_source: pretrained # Load ImageNet weights initially
  device: "cuda" # Default device for model placement

# --- 5. TRAINER EXECUTION (DDP Control) ---
trainer:
  type: "cnn_trainer"
  epochs: 20
  batch_size: 64

  # Distributed Parallelism Configuration
  distributed:
    backend: "nccl"
    world_size: 4 # Expected number of GPUs/processes (CRITICAL for DDP setup)

  optimizer:
    type: "AdamW"
    learning_rate: 0.00005
    weight_decay: 0.01

  checkpoint:
    save_path: "s3://cv-model-artifacts/checkpoints/"
    frequency_epochs: 5
    max_checkpoints: 3

# --- 6. EVALUATOR CONFIGURATION (Used by EvaluationOrchestrator) ---
evaluator:
  primary_metric: "f1_score" # Metric used by Model Selector
  reporting_level: "detailed"
  metrics:
    - name: "accuracy"
    - name: "f1_score"
      params:
        average: "weighted"
        num_classes: 3

# --- 7. DATASET SPLIT CONFIGURATION (New required section for CVDataset) ---
datasets:
  # Training Dataset
  train:
    metadata_source: "s3://cv-training-data-bucket/manifests/train_manifest_v1.csv"
    shuffle_data: True

  # Validation Dataset
  validation:
    metadata_source: "s3://cv-training-data-bucket/manifests/val_manifest_v1.csv"
    shuffle_data: False

  # Test Dataset (Optional)
  test:
    metadata_source: "s3://cv-training-data-bucket/manifests/test_manifest_v1.csv"
    shuffle_data: False
